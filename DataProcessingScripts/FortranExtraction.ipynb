{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction of Henry's Law Constants from Fortran 90 file\n",
    "\n",
    "Version: 0.3.0\n",
    "\n",
    "Some code adapted from https://github.com/jtd1g16/HLC_Prediction \n",
    "\n",
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "from MyFunctions.IdentifierConversion import convertors as conv\n",
    "import json\n",
    "from rdkit import RDLogger\n",
    "from itertools import islice\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "import numpy as np\n",
    "import cirpy as cp\n",
    "from rdkit import Chem\n",
    "import pubchempy as pcp\n",
    "import requests\n",
    "import time as t\n",
    "\n",
    "vers = \"2.7.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the file and converting it to a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of species: 10173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10173/10173 [00:00<00:00, 58745.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dictionary entries: 10173\n",
      "Number of missing temperatures: 40862\n",
      "Number of temperatures: 45221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def rawToDict(file):\n",
    "    \"\"\" \n",
    "    Takes the fortran file and returns a dictionary with the species name as the key and a dictionary with the CAS number,\n",
    "    the constants, and the types of constants as the value.\n",
    "    \n",
    "    Parameters:\n",
    "    file: file object\n",
    "        The fortran file containing the Henry's Law constants.\n",
    "        \n",
    "    Returns:\n",
    "    consDict: dictionary\n",
    "        A dictionary with the species name as the key and a dictionary with the CAS number, the constants, and the types of constants as the value.\n",
    "    \"\"\"\n",
    "    missingTempCounter = 0\n",
    "    numberOfTemps = 0\n",
    "\n",
    "    speciesSubset = file.read().split(sep = \"! species:\") #Split the file into a list to separate each species\n",
    "    print(\"Number of species:\", len(speciesSubset) - 1) #Print the number of species in the file\n",
    "    consDict = {} #Initialize the dictionary to store the species name, CAS number, constants, and types of constants\n",
    "    for lines in tqdm(speciesSubset[1:]): #Reading the data from each species #CHANGE TO [1:] TO READ ALL\n",
    "        speciesLine = lines.split(sep = \"\\n\")[0] #Separating the line with the name\n",
    "        speciesName = speciesLine[1:].strip() #Storing name\n",
    "\n",
    "        inchiLine = lines.split(sep = \"\\n\")[4] #Separating the line with the InChI\n",
    "        inchiKey = inchiLine.split(sep='! inchikey: ')[1].strip() #Storing InChI\n",
    "\n",
    "        casLine = lines.split(sep = \"\\n\")[3] #Separating the line with the CAS\n",
    "        casNum = casLine.split(sep='! casrn:   ')[1].strip() #Storing CAS\n",
    "\n",
    "        consTypes = []; consList = []; temps = [] #Creating lists for constants\n",
    "        consLines = lines.split(sep=\"\\n\")[5:] #Separating constant lines\n",
    "        for i in range(len(consLines)): #Iterating through lines \n",
    "            if \"HscpSI\" in consLines[i]: #Checking HscpSI is present\n",
    "                consTypes.append(consLines[i].split(sep='type: ')[1].split(sep=',')[0]) #Data type\n",
    "                consList.append(consLines[i].split(sep='=  ')[1][0:8].strip()) #Constant\n",
    "\n",
    "                temp = consLines[i].split(sep='=  ')[1][14:21].strip()\n",
    "                if temp == \"\": #Assuming temperature is 25C if not listed\n",
    "                    temp = \"298.15\"\n",
    "                    missingTempCounter += 1\n",
    "                temps.append(float(temp)-273.15) #Temperature\n",
    "                numberOfTemps += 1\n",
    "            \n",
    "        consDict[speciesName] = {\"Compound\" : speciesName, #Constructing the dictionary\n",
    "                                \"InChIKey\" : inchiKey,\n",
    "                                \"CAS\"       : casNum,\n",
    "                                \"Constants\" : consList, \n",
    "                                \"Types\" : consTypes,\n",
    "                                \"Temperature\" : temps}\n",
    "\n",
    "    print(\"Number of dictionary entries:\", len(consDict))\n",
    "\n",
    "    print(\"Number of missing temperatures:\", missingTempCounter)\n",
    "    print(\"Number of temperatures:\", numberOfTemps)\n",
    "    return consDict\n",
    "\n",
    "try:\n",
    "    with open(f\"../Data/SourceData/{vers}-HLExtractedFull.json\", \"r\") as file: #Checking if json file already exists\n",
    "        consDict = json.load(file)\n",
    "    file.close()\n",
    "    print(\"Dictionary loaded from file\")\n",
    "\n",
    "except:\n",
    "    with open(\"../Data/SourceData/HscpSI.f90\", \"r\") as file: #Reading fortran file and converting to dict\n",
    "        consDict = rawToDict(file) \n",
    "    file.close()\n",
    "\n",
    "    with open(f\"../Data/SourceData/{vers}-HLExtractedFull.json\", \"w\") as file: #Writing dictionary to json file\n",
    "        json.dump(consDict, file)\n",
    "    file.close()\n",
    "\n",
    "    pd.DataFrame(consDict).T.reset_index(drop=True).to_csv(f\"../Data/SourceData/{vers}-HLExtractedFull.csv\", index=False) #Writing dictionary to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def casToX(idList1, idList2, idList3, target):\n",
    "        \"\"\" \n",
    "        This function converts CAS to canonical SMILES/InChI strings using cirpy.\n",
    "        \n",
    "        Parameters:\n",
    "        casList: list of strings\n",
    "        target: string\n",
    "\n",
    "        Returns:\n",
    "        targVals: list of strings\n",
    "        \"\"\"\n",
    "\n",
    "        # validateTarget(target)\n",
    "\n",
    "        targVals = []\n",
    "        for i in tqdm(range(len(idList1)), desc=f\"Converting identifier to {target}\"):\n",
    "            id1 = idList1[i]; id2 = idList2[i]; id3 = idList3[i]\n",
    "            toTry = [id1, id2, id3]\n",
    "            output = []\n",
    "\n",
    "            for id in toTry:\n",
    "                try:\n",
    "                    if id != \"UNKNOWN\":\n",
    "                        val = cp.resolve(id, target)\n",
    "                        if val != \"O\" or val == np.nan: #It should never be water for this dataset\n",
    "                            output.append(val)\n",
    "                            break\n",
    "                        else:\n",
    "                            output.append(np.nan)\n",
    "\n",
    "                    else: #If the identifier is \"UNKNOWN\", then the value is np.nan\n",
    "                        print(f\"Error with {id}. Trying next identifier.\")\n",
    "                        output.append(np.nan)\n",
    "                except:\n",
    "                    print(f\"Error with {id}. Trying next identifier.\")\n",
    "                \n",
    "            if len(output) == 3 and all([x == np.nan for x in output]):\n",
    "                print(f\"Error with {id1}, {id2}, and {id3}.\")\n",
    "                targVals.append(np.nan)\n",
    "            else:\n",
    "                targVals.append(output[0])\n",
    "        return targVals\n",
    "\n",
    "\n",
    "def smilesToInChI(smiles, nameList, casList):\n",
    "    \"\"\" \n",
    "    This function converts SMILES to InChI strings and adds them to the dataframe. Where an InChI string cannot be found, a nan is added.\n",
    "    \n",
    "    Parameters:\n",
    "    smiles: list of strings\n",
    "    \n",
    "    Returns:\n",
    "    InChI: list of strings\n",
    "    \"\"\"\n",
    "    RDLogger.DisableLog('rdApp.*')\n",
    "    nErrors = 0; InChI = []\n",
    "    \n",
    "    for i in tqdm(range(len(smiles)), desc=\"Converting SMILES to InChI\"): #Iterating through the SMILES strings and converting them to InChI strings\n",
    "        try:\n",
    "            mol = Chem.MolFromSmiles(smiles[i]) #Convert to mol object then add inchi to list\n",
    "            inchival = Chem.MolToInchi(mol)\n",
    "        except:\n",
    "            inchival = np.nan\n",
    "\n",
    "        if type(inchival) != float: #If the InChI is not found, then try other identifiers\n",
    "            InChI.append(inchival)\n",
    "        else:\n",
    "            print(\"InChI not found for\", smiles[i], \"trying other identifiers\")\n",
    "            valList = casToX([nameList[i]], [smiles[i]], [casList[i]], \"stdinchi\")\n",
    "\n",
    "            if valList[0] != np.nan:\n",
    "                InChI.append(valList[0])\n",
    "            else:\n",
    "                InChI.append(np.nan) #Adding nan and incrementing the error count\n",
    "                print(\"No InChI available for\", nameList[i])\n",
    "                nErrors += 1\n",
    "    print(nErrors, \"errors occurred\")\n",
    "\n",
    "    return InChI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the CAS and InChI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting identifier to smiles:   0%|          | 0/10173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting identifier to smiles:   1%|          | 81/10173 [00:48<2:18:19,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with RQNWIZPPADIBDY-UHFFFAOYSA-N. Trying next identifier.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting identifier to smiles:   1%|          | 94/10173 [00:59<2:04:07,  1.35it/s]"
     ]
    }
   ],
   "source": [
    "# consDict = dict(islice(consDict.items(), 300)) #Limiting the number of species to 10 for testing\n",
    "\n",
    "inchiList = [consDict[key]['InChIKey'] for key in consDict.keys()] #Extracting CAS numbers for casToSmiles function\n",
    "casList = [consDict[key]['CAS'] for key in consDict.keys()] #Extracting CAS numbers for casToSmiles function\n",
    "nameList = [consDict[key]['Compound'] for key in consDict.keys()] #Extracting CAS numbers for casToSmiles function\n",
    "\n",
    "try: #Reading SMILES from file if it exists, or generating SMILES from CAS numbers\n",
    "    with open(f\"../Data/Processed/{vers}-HL_SMILES.txt\", \"r\") as infile:\n",
    "        smiles = eval(infile.read())\n",
    "    infile.close()\n",
    "except:\n",
    "    smiles = casToX(inchiList, casList, nameList, \"smiles\")\n",
    "    with open(f\"../Data/Processed/{vers}-HL_SMILES.txt\", \"w\") as outfile:\n",
    "        for i in range(len(smiles)):\n",
    "            outfile.write(str(smiles[i]) + '\\n')\n",
    "    outfile.close()\n",
    "\n",
    "print(len(smiles), \"SMILES\")\n",
    "\n",
    "try: #Reading InChI from file if it exists, or generating InChI from SMILES\n",
    "    with open(f\"../Data/Processed/{vers}-HL_InChI.txt\", \"r\") as infile:\n",
    "        InChI = infile.read().split(sep = '\\n')\n",
    "    infile.close()\n",
    "    InChI = [InChI[i] for i in range(len(InChI) - 1)]\n",
    "except:\n",
    "    InChI = smilesToInChI(smiles, nameList, casList)\n",
    "    with open(f\"../Data/Processed/{vers}-HL_InChI.txt\", \"w\") as outfile:\n",
    "        for i in range(len(InChI)):\n",
    "            outfile.write(str(InChI[i]) + '\\n')\n",
    "    outfile.close()\n",
    "\n",
    "print(len(InChI), \"InChI\")\n",
    "\n",
    "for key in consDict.keys(): #Adding SMILES and InChI to the dictionary\n",
    "    consDict[key]['SMILES'] = smiles[inchiList.index(consDict[key]['InChIKey'])]\n",
    "    consDict[key]['InChI'] = InChI[inchiList.index(consDict[key]['InChIKey'])]\n",
    "\n",
    "with open(f\"../Data/Processed/{vers}-HL_AllDTypes.json\", \"w\") as outfile: #Writing dictionary to json file\n",
    "    json.dump(consDict, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averageTemperatureValues(removedTypes, consDict):\n",
    "    \"\"\"\n",
    "    Averages the Henry's Law constants for each compound at different temperatures.\n",
    "\n",
    "    Parameters:\n",
    "    removedTypes: list\n",
    "        A list of types of constants to remove from the dictionary.\n",
    "    consDict: dictionary\n",
    "        A dictionary with the species name as the key and a dictionary with the CAS number, the constants, and the types of constants as the value.\n",
    "\n",
    "    Returns:\n",
    "    consDict: dictionary\n",
    "        A dictionary with the species name as the key and a dictionary with the CAS number, the constants, and the types of constants as the value.\n",
    "    \"\"\"\n",
    "\n",
    "    for compound in consDict.keys(): #Iterating through compounds\n",
    "        df = pd.DataFrame(consDict[compound]) #Creating a dictionary to make it easier to drop dubious values\n",
    "        for t in removedTypes:\n",
    "            df = df.drop(df[df[\"Types\"] == t].index) #Removing rows with X as the type\n",
    "            # print(f\"Removed type {t}, resulting shape:\", df.shape)\n",
    "\n",
    "        temperatureDict = {} #Initialising dict\n",
    "        temperatures = df[\"Temperature\"].values\n",
    "\n",
    "        for i in range(len(temperatures)): #Iterating through temperatures\n",
    "            try:\n",
    "                temperatureDict[temperatures[i]].append(df[\"Constants\"].values[i]) #Adding constant to temperature as list\n",
    "            except:\n",
    "                temperatureDict[temperatures[i]] = [df[\"Constants\"].values[i]]\n",
    "\n",
    "        for key in list(temperatureDict.keys()): #Calculating the mean of the constants at each temperature\n",
    "            values = temperatureDict[key]\n",
    "            values = [float(i) for i in values]\n",
    "            temperatureDict[key] = np.mean(values)\n",
    "\n",
    "        consDict[compound][\"Constants\"] = list(temperatureDict.values()) #Updating dictionary\n",
    "        consDict[compound][\"Temperature\"] = list(temperatureDict.keys())\n",
    "        del consDict[compound][\"Types\"] #Removing types (now redundant)\n",
    "\n",
    "    return consDict\n",
    "\n",
    "with open(f\"../Data/Processed/{vers}-HL_AllDTypes.json\", \"r\") as outfile: #Writing dictionary to json file\n",
    "    consDict = json.load(outfile)\n",
    "outfile.close()\n",
    "\n",
    "removedTypes = [\"C\", \"X\", \"?\", \"E\"] # Original types to remove\n",
    "# removedTypes = [\"V\", \"R\", \"T\", \"C\", \"X\", \"?\", \"E\"] #Stricter types to remove\n",
    "consDict = averageTemperatureValues(removedTypes, consDict)\n",
    "\n",
    "with open(f\"../Data/Processed/{vers}-HenrysLaw.json\", \"w\") as outfile: #Saving updated dictionary\n",
    "    json.dump(consDict, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset with expanded lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josh_\\AppData\\Local\\Temp\\ipykernel_15804\\4219278837.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataset = pd.concat([dataset, df], axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12255, 7)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.DataFrame(columns=list(consDict[\"ozone\"].keys())) #Creating a new dataframe to store the data\n",
    "\n",
    "for key in consDict.keys(): #Creating a dataframe for each species + concatenating\n",
    "    try:\n",
    "        df = pd.DataFrame.from_dict(consDict[key])\n",
    "        dataset = pd.concat([dataset, df], axis=0)\n",
    "    except: #If there is an error, print the key and the dictionary\n",
    "        print(key)\n",
    "        print(consDict[key])\n",
    "\n",
    "dataset.reset_index(drop=True, inplace=True) #Saving\n",
    "print(dataset.shape)\n",
    "dataset.head()\n",
    "dataset.to_csv(f\"../Data/Processed/{vers}-HenrysLaw.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Constants</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.225500e+04</td>\n",
       "      <td>12255.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.031879e+35</td>\n",
       "      <td>1416.951183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.197827e+37</td>\n",
       "      <td>2876.725505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.000000e-14</td>\n",
       "      <td>-6973.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000e-03</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.485000e+03</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.535500e+39</td>\n",
       "      <td>28726.850000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Constants   Temperature\n",
       "count  1.225500e+04  12255.000000\n",
       "mean   3.031879e+35   1416.951183\n",
       "std    3.197827e+37   2876.725505\n",
       "min    8.000000e-14  -6973.150000\n",
       "25%    7.000000e-03     25.000000\n",
       "50%    1.000000e+00     25.000000\n",
       "75%    4.485000e+03     25.000000\n",
       "max    3.535500e+39  28726.850000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\josh_\\Documents\\GitHub\\HenrysLaw\\.venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Compound       12255\n",
       "InChIKey       12255\n",
       "CAS            12255\n",
       "Constants      12255\n",
       "Temperature    12255\n",
       "SMILES          9156\n",
       "InChI           9578\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(dataset.notnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InChI\n",
       "InChI=1S/C7H8/c1-7-5-3-2-4-6-7/h2-6H,1H3                           24\n",
       "InChI=1S/C6H6/c1-2-4-6-5-3-1/h1-6H                                 21\n",
       "InChI=1S/C2H3Cl3/c1-2(3,4)5/h1H3                                   20\n",
       "InChI=1S/C2HCl3/c3-1-2(4)5/h1H                                     20\n",
       "InChI=1S/C3H6O/c1-3(2)4/h1-2H3                                     18\n",
       "                                                                   ..\n",
       "InChI=1S/C9H16O2/c1-3-5-9(11)7-6-8(10)4-2/h3-7H2,1-2H3              1\n",
       "InChI=1S/C9H12O2/c1-9(2)5-3-6(9)8(11)4-7(5)10/h5-6H,3-4H2,1-2H3     1\n",
       "InChI=1S/C8H8O2/c1-5-3-8(10)6(2)4-7(5)9/h3-4H,1-2H3                 1\n",
       "InChI=1S/C8H8O2/c1-2-6-5-7(9)3-4-8(6)10/h3-5H,2H2,1H3               1\n",
       "InChI=1S/3C2H5.ClH.Pb/c3*1-2;;/h3*1H2,2H3;1H;/q;;;;+1/p-1           1\n",
       "Name: count, Length: 6995, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"InChI\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
